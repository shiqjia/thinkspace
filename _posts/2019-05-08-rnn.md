---
title: RNN理解及实现
# image: /images/black_hawk.png
categories:
  - dnn
tags:
  - dnn
last_modified_at: 2019-05-08T13:57:52-17:00
---

## 背景
梳理从rnn->lstm->gru->attention的理论及代码，希望通过把知识串联起来，形成自己的知识体系。   
ps：本篇主要结合李宏毅老师的课程和自己的理解梳理

## RNN

### 为什么需要RNN？
假设有一个订票系统，可以通过我说一段话，判断我的出发地和出发时间。如果我说："我要订5月1日到北京的飞机票"，通过训练一个一般的网络模型，它可以学得北京是地点，5月1日是日期。但是如果我说"我要订5月1日离开北京的机票"，模型还是只能识别出北京是出发地，因为这个时候模型只能关注到北京是地点，不能关注到上下文"离开"。     
所以为了解决这种包含语序（时间顺序）的问题就提出了RNN.

### RNN是怎么做的？
RNN实际上就是在原来的基础上加入了时序，在t时刻同时读取输入x，和之前存储的"记忆"。    
![img]({{"images/picture/RNN/rnn-1.png" | relative_url }})

虽然都是词语 taibei，但是这两个词的上下文不同（分别为“leave”和“arrive”）,所以“记忆”ai不同，这样得到的slot是台北的概率也不同，就能解决之前提到的不能区分哪个词应该填到slot的问题。

### RNN的分类
elman network: 在t+1时刻，读取$$ x_{t+1} $$和$$ h_{t} $$(隐藏层)
jordan network: 在t+1时刻，读取$$ x_{t+1} $$和$$ y_{t} $$（输出）  
![img]({{"images/picture/RNN/rnn-2.png" | relative_url }})        
双向rnn   
![img]({{"images/picture/RNN/rnn-3.png" | relative_url }})      

### RNN的问题  
![img]({{"images/picture/RNN/rnn-4.png" | relative_url }})
由于RNN循环的时候是共享参数的（权重），所以当时序很长的时候，会出现梯度消失或者梯度爆炸的问题

## LSTM

### LSTM和RNN的区别
- 和simpleRNN相比，LSTM多了3个门：input/ output/ forget gate，最终控制模型的输出，什么时候打开，打开多少是网络自己学习的. 由于simpleRNN只有1个输入，而LSTM有4个输入，且每个输入都使用不同的w和b，所以LSTM的参数量是simpleRNN的4倍。   
- LSTM  由于有做加法（只要forget gate被打开就会做加法,所以一般会给forget gate 一个比较大的biaes，确保被打开），所以能解决梯度消失的问题，但是不能避免梯度爆炸的问题          
![img]({{"images/picture/RNN/lstm-1.png" | relative_url }})
    
### LSTM结构
详细可以看图：  
![img]({{"images/picture/RNN/lstm-2.png" | relative_url }})   
  
g(z)，f(zi)，f(zo) ,f(zf):都是输入z,wx+b之后，经过激活函数（不同的f的w,b不同）  
f(zi)，f(zo) ,f(zf)可以看做分别控制input多少的信号，output多少的信号，forget多少的信号

举例说明如下：  
![img]({{"images/picture/RNN/lstm-3.png" | relative_url }})  
1）输入3，f(zi)=1,f(zf)=1; g(z)f(zi)+cf(zf)=3\*1+0\*1=3,更新c=3,f(zo)=0，输出门关闭，输出为0  
2）输入4，f(zi)=1,f(zf)=1；g(z)f(zi)+cf(zf)=4\*1+3\*1=7，更新c=7,f(zo)=0,输出门关闭，输出为0   
3）输入2，f(zi)=0,f(zf)=1；g(z)f(zi)+cf(zf)=0\*1+7\*1=7，更新c=7,f(zo)=0,输出门关闭，输出为0   
4）输入1，f(zi)=0,f(zf)=1；g(z)f(zi)+cf(zf)=0\*1+7\*1=7，更新c=7,f(zo)=1,输出门打开，输出为7   
5）输入3，f(zi)=0,f(zf)=0；g(z)f(zi)+cf(zf)=0\*1+7\*0=7，更新c=0,f(zo)=0,输出门关闭，输出为0 

### LSTM时序的体现

![img]({{"images/picture/RNN/lstm-4.png" | relative_url }})  
 这里的zf,zi,z,zo都是向量，向量的每个维度对应不同时刻的值，有多少个时刻，向量的维度就是多少。    
![img]({{"images/picture/RNN/lstm-5.png" | relative_url }})  
 这里的ct-1的计算要依据上一个时刻的数据，而且在实际的lstm的计算中，输入部分除了xt，还有输出之前的hidden state ht和ct，将这3者拼接在一起作为输入。  
![img]({{"images/picture/RNN/lstm-6.png" | relative_url }})  

### LSTM的问题
- LSTM有3个门，参数较多，存在比较高的过拟合风险。
- 要求输入序列和输出序列等长


## GRU

### GRU和LSTM的区别
GRU只有两个门：reset gate和update gate，参数较少。使用GRU能够达到与LSTM相当的效果，并且相比之下更容易进行训练，能够很大程度上提高训练效率，因此很多时候会更倾向于使用GRU。

### GRU结构
![img]({{"images/picture/RNN/gru-1.png" | relative_url }})  
![img]({{"images/picture/RNN/gru-2.png" | relative_url }})  
$$ h^{t}=z\bigodot h^{t-1} +(1-z)\bigodot h^{'} $$  
- $$ z\bigodot h^{t-1} $$ :表示对原本隐藏状态的选择性“遗忘”。这里的z可以想象成遗忘门（forget gate），忘记 $$ h^{t-1} $$维度中一些不重要的信息。
- $$ (1-z)\bigodot h^{'} $$: 表示对包含当前节点信息的 $$ h^{'} $$进行选择性”记忆“。与上面类似，这里的 (1-z) 同理会忘记 $$ h^{'} $$ 维度中的一些不重要的信息。或者，这里我们更应当看做是对 $$ h^{'} $$ 维度中的某些信息进行选择。
- 这里的遗忘 z 和选择 (1-z) 是联动的。也就是说，对于传递进来的维度信息，我们会进行选择性遗忘，则遗忘了多少权重（1-z），我们就会使用包含当前输入的 $$ h^{'} $$ 中所对应的权重进行弥补 (1-z)。以保持一种”恒定“状态。
- 使用同一个门控信号z就可以进行遗忘和记忆选择。


## Encoder-decoer(seq2seq)

### 背景
RNN有多种结构：
- 1 to 1:最基本的单层网络，输入是x，经过变换Wx+b和激活函数f得到输出y
- 1 to n:输入不是序列而输出为序列的情况，只在序列开始进行输入计算.例如：图像生成文字;类别生成音乐
- n to n:输入、输出都是等长的序列数据,经典RNN。例如：计算视频中每一帧的分类标签。
- n to 1:输入一个序列，输出一个单独的值。例如：处理序列分类问题，例如语音或者文本分类

- n to m:Encoder-decoer。例如：机器翻译

### 结构
![img]({{"images/picture/RNN/ed-1.png" | relative_url }})   
- x表示输入句子，$$ x=(x_{1},x_{2},...x_{m}) $$；y表示目标句子 $$ y=(y_{1},y_{2},...y_{n}) $$
- Encoder:对输入句子x进行编码，通过非线性变换转换为中间语义表示c
- Decoder:根据句子x的中间语义表示c和之前已经产生的历史信息$$ y_{1},y_{2},...y_{i-1} $$来生当前时刻要生成的$$ y_{i} $$
备注:Decoder 和encoder可以选择不同的模型，比如CNN/RNN/BiRNN/GRU/LSTM/Deep LSTM等

### Encoder-decoer的问题   
在生成单词y1,y2,y3的时候，使用的句子x的语义编码c都是一样的，而编码c是由句子x的每个单词经过encoder编码产生的，这意味着句子x中任意单词对生成某个目标单词yi来说影响力是相同的（如果是rnn的话，理论上后输入的单次影响力更大）。
当句子很长时，所有的语义完全通过中间语义向量表示，会丢失很多细节信息，这也是为何要引入注意力模型的原因。


## Attention

### Attention的结构
![img]({{"images/picture/RNN/att-1.png" | relative_url }})  
attention 由原来的固定的语义编码c，变成了根据当前生成单次不断变化的ci

例如： 
![img]({{"images/picture/RNN/att-2.png" | relative_url }})  
f2表示encoder对输入英文单词的某种变换函数，如果encoder用的是rnn模型，f2一般是某个时刻输入xi后隐藏层节点的状态值，g表示encoder根据单词的中间表示合成整个句子中间语义表示的变换函数

翻译tom的时候，$$ c_{i} $$ 的形成过程如下：   
![img]({{"images/picture/RNN/att-3.png" | relative_url }})

### 如何得到注意力分配概率分布值？
![img]({{"images/picture/RNN/att-4.png" | relative_url }})  
通过函数$$F(hj,hi-1)$$来获得目标单词yi和每个输入单词对应的对其可能性，不同的论文中会采用不同的方法

### Attrntion的优缺点
- 优点：
    - 在机器翻译时，不只是关注全局的语义向量c，增加了“注意力范围”。表示接下来输出的词要重点关注输入序列种的哪些部分。根据关注的区域来产生下一个输出。
    - 不要求编码器将所有信息全输入在一个固定长度的向量中。  
    - 将输入编码成一个向量的序列，解码时，每一步选择性的从序列中挑一个子集进行处理。
    - 在每一个输出时，能够充分利用输入携带的信息，每个语义向量Ci不一样，注意力焦点不一样。
- 缺点：
    - 需要为每个输入输出组合分别计算attention。50个单词的输出输出序列需要计算2500个attention。
    - attention在决定专注于某个方面之前需要遍历一遍记忆再决定下一个输出是以什么。
    
    
### Attention 抽象
![img]({{"images/picture/RNN/att-5.png" | relative_url }})
- 通过计算Query和各个Key的相似性或者相关性，得到每个Key对应Value的权重系数，
- 对value值进行归一化处理
- 对value进行加权求和，得到最终的attention数值


### self-attention
之前所说的attention 的source和target是不一样的，例如英文句子翻译成中文，self-attention可以理解为target=source,self-attention的好处，以机器翻译为例：  
![img]({{"images/picture/RNN/att-6.png" | relative_url }})  
self-attention可以捕获有一定距离的短语结构

## 代码实现
https://github.com/wenshiqi/DL_laboratory/tree/master/Rnn


## 参考
https://zhuanlan.zhihu.com/p/32481747
https://www.jiqizhixin.com/articles/2018-12-14-4
https://blog.csdn.net/malefactor/article/details/78767781
https://blog.csdn.net/qq_31456593/article/details/71110452